# 集群

- ES 可以只部署单个实例，也可以部署多个实例组成分布式集群，从而获得更大的容量、更高的性能，还可通过冗余节点提高可用性。

## 节点

- 一个 ES 集群（cluster）中的每个 ES 实例称为一个节点（node）。
- 集群中有且仅有一个主节点，负责管理集群，比如增删索引、分配分片给节点。

- 一个 ES 节点可以担任多种角色：
  - `master`
    ：主资格节点（master-eligible），有资格被选为主节点。
    只有主资格节点可以参与主节点的选举投票。
  - `data`
    ：数据节点，负责存储数据，支持增删查改、聚合等操作。
    master 和 data 角色的节点都需要访问 ES 的 `path.data` 目录。
  - `ingest`
    ：摄取节点，负责将管道应用于文档，以便在建立索引之前加工文档。
  - `ml`
    ：机器学习节点。集群至少拥有一个此类节点才能提供机器学习功能。
  - `remote_cluster_client`
    ：远程集群节点，可以连接到远程集群，作为其客户端。
  - `transform`
    ：转换节点。集群至少拥有一个此类节点才能提供转换功能。
  - `coordinating`
    ：协调节点。它是每个节点的隐式角色，不能取消。
    每个节点都知道各个文档存储在哪个节点上，也默认可以处理用户的 HTTP 请求。
    因此用户可以向任意节点发出查询请求，该节点会将请求转发给存储相应文档的数据节点（可能有多个），然后将查询结果返回给用户。

- 节点的默认角色配置如下：
  ```yml
  node.master: true
  node.voting_only: false   # 是否只参与主节点选举，不能担任主节点
  node.data: true
  node.ingest: true
  node.ml: true
  cluster.remote.connect: true
  ```

- 在以下情况下，主资格节点会发起主节点的选举：
  - 发现它自己不是主节点。
  - 询问其它节点，发现大家都没有连接到主节点。
  - 发现有至少 `discovery.zen.minimum_master_nodes` 个主资格节点没有连接到主节点。
    该参数的默认值为：` 主资格节点总数/2 + 1`

- ES 集群的高可用方案：
  - 部署至少 3 个主资格节点，其中至少 2 个节点为 `node.voting_only: false` ，从而可以通过选举更换主节点。
  - 不能同时停止 50% 数量的主资格节点，否则集群会不能投票决策。但可以分多次停止。
  - 让每个节点专注于一种角色，以减少不相关的工作负担。比如配置专用的主节点：
    ```yml
    node.master: true
    node.voting_only: false
    node.data: false
    node.ingest: false
    node.ml: false
    cluster.remote.connect: false
    ```

## 分片

- ES 会将每个新增的索引划分成多个分片（shard），该索引下新增的文档会平均分配到各个分片中，而所有分片会分散存储到各个节点中。
  - 分片是 ES 存储数据的最小单位。
  - 当集群扩容或缩容时，ES 会自动迁移分片，均衡地存储到各个节点。
  - 单个分片的存储容量理论上没有上限，但是存储的文档越多，会导致查询耗时越久。
  - 当用户查询某个文档时，ES 会先找到存储该文档的分片，然后读取该文档的内容，返回给用户。

- 分片分为两类：
  - 主分片（primary shard）
    - ：用于存储某个索引的数据。
    - 每个索引可以划分 1 个或多个主分片。
  - 副分片（replica shard）
    - ：主分片的副本，只支持读请求，不支持写请求。
    - 每个主分片可以有 0 个或任意个副分片。

- 在创建索引时可以设置其分片数量，如下：
  ```sh
  PUT /student                    # 这里只能使用 PUT 方法
  {
    "settings" : {
        "number_of_shards" : 3,   # 给该索引划分 3 个主分片
        "number_of_replicas" : 1  # 给每个主分片创建 1 个副分片
    }
  }
  ```
  - 创建了索引之后就不能再修改其分片数量。


## 相关 API

- 查看 ES 集群的状态：
  ```sh
  [root@Centos ~]# curl -X GET 127.0.0.1:9200/_cluster/health?pretty
  {
    "cluster_name" : "elasticsearch",
    "status" : "yellow",            # 集群的状态
    "timed_out" : false,
    "number_of_nodes" : 1,          # 节点的数量
    "number_of_data_nodes" : 1,     # 数据节点的数量
    "active_primary_shards" : 4,    # 主分片的数量
    "active_shards" : 4,            # 分片的数量
    "relocating_shards" : 0,
    "initializing_shards" : 0,
    "unassigned_shards" : 4,        # 未分配的分片的数量
    "delayed_unassigned_shards" : 0,
    "number_of_pending_tasks" : 0,
    "number_of_in_flight_fetch" : 0,
    "task_max_waiting_in_queue_millis" : 0,
    "active_shards_percent_as_number" : 50.0
  }
  ```
  - status 的可能取值：
    - `green` ：所有主分片、副分片都可用。
    - `yellow` ：所有主分片都可用，但存在不可用的副分片。
    - `red` ：存在不可用的主分片。
  - 副分片不会被分配到主分片所在节点上，因为那样不能实现灾备。如果集群内没有其它节点了，副分片就会一直处于未分配状态。

- 列出所有 node 的信息：
  ```sh
  [root@Centos ~]# curl 127.0.0.1:9200/_cat/nodes?v
  ip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
  10.0.0.1             11          85   1    0.06    0.09     0.18 dilm      *      node_1
  ```

## 部署集群

- 部署 ES 集群时，需要在它们的配置文件中加入如下配置：
  ```yml
  discovery.seed_hosts:   # 声明该集群的所有节点，默认值为 127.0.0.1、[::1]
  - 10.0.0.1:9300
  - 10.0.0.2:9300
  - 10.0.0.3:9300
  ```
  - ES 服务器启动之后，会自动检查这些节点，如果存在其它 ES 服务器，并且拥有相同的集群名，则组成同一个集群。

- 如果是部署一个全新的 ES 集群，还需要声明主资格节点：
  ```yml
  initial_master_nodes:
  - node-1
  - node-2
  - node-3
  ```

