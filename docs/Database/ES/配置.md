# 配置

## index template

：索引模板。用于在创建索引时进行初始化配置。
- 创建索引时，会根据索引模式匹配索引模板。如果存在多个匹配的索引模板，则采用优先级最高的那个。
  - 创建索引时，如果加上了配置信息，则会覆盖索引模板中的对应配置。
  - 创建、修改索引模板时，只会影响之后新创建的索引，不会影响已创建的索引。

- 相关 API ：
  ```sh
  GET     /_template                            # 查询所有的索引模板
  GET     /_template/<template>                 # 查询指定的索引模板
  PUT     /_template/<template>  <request_body> # 创建索引模板
  DELETE  /_template/<template>                 # 删除索引模板
  ```

- 例：创建一个索引模板
  ```sh
  PUT /_template/my_template_1
  {
    "index_patterns": ["mysql-log-*", "nginx-log-*"], # 索引模式，用于匹配一些索引
    "aliases": {...},
    "settings": {...},
    "mappings": {...},
    # "version" : 1,                  # 声明该索引模板的版本
    # "_meta": {                      # 配置该索引模板的元数据，可以加入任意名称的参数，并不会被 ES 使用
    #   "description": "This is a log template."
    # }
  }
  ```
  - 至少要声明 index_patterns ，其它配置则可以省略。

- v7.8 版本引入了可组合模板，API 为 _index_template 。
  - 可设置 `"priority": 100` 参数，表示该模板的优先级。
    - 默认为 0 ，即优先级最低。
    - 如果一个索引匹配多个索引模板，则采用优先级最高的那个。

### index pattern

：索引模式。一个用于匹配任意个索引名的字符串。
- 可以是以下格式：
  ```sh
  my-index-1                      # 一个索引名
  my-index-1,my-index-2           # 多个索引名，用逗号分隔
  my-index-*                      # 可以使用通配符 * 匹配多个索引名
  my-index-*,-my-index-2          # 可以在索引名之前加上 - ，从而排除它
  ```

### alias

- 每个索引可以创建一个或多个别名（alias）。
  - ES 的大多数 API 都支持输入索引的别名，会自动解析到原名。
- 相关 API ：
  ```sh
  GET   /_alias                     # 查询所有索引的所有别名
  GET   /_alias/<alias>             # 加上一个 alias 名称进行筛选，支持使用通配符 *
  GET   /<index>/_alias             # 查询指定索引的所有别名
  GET   /<index>/_alias/<alias>

  HEAD  /_alias/<alias>             # 检查索引是否存在
  HEAD  /<index>/_alias/<alias>

  PUT   /<index>/_alias/<alias>     # 给索引创建别名

  DELETE  /<index>/_alias/<alias>   # 删除索引的别名
  ```

### mappings

：映射，用于定义索引下文档的数据结构、字段类型。
- 定义方式分为两种：
  - dynamic mapping
    - ：动态映射，是根据匹配条件，同时定义任意个字段。
  - explicit mapping
    - ：显式映射，是根据字段名，定义某个字段。
    - index 在创建之后，不能修改 explicit mapping 中已有的字段，只能增加字段。也可以根据新 mappings 创建一个新 index ，然后将旧 index 的文档通过 reindex 拷贝过去。
- 例：
  ```sh
  "mappings": {
    "_source": {
      "enabled": true       # 是否保存 _source 字段
    },
    "dynamic_templates" : [               # 动态映射
      {
        "integer_fields": {
          "match_mapping_type": "long",   # 匹配字段值的数据类型
          "mapping": {                    # 配置匹配的字段的映射
            "type": "integer"             # 该效果为：如果新增的文档中，任意字段满足匹配条件，则存储为 integer 数据类型
          }
        }
      },
      {
        "string_fields" : {
          "match_mapping_type" : "string",
          # "match" : "*",                # 匹配字段名
          # "path_match" : "message",     # 匹配字段的路径
          "mapping" : {
            "type" : "text"
          }
        }
      }
    ],
    "properties": {                       # 显式映射
      "@timestamp" : {
        "type" : "date"
      },
      "level" : {
        "type" : "text",
        "fields" : {                      # 子字段
          "keyword" : {
            "type" : "keyword",
            "ignore_above" : 256
          }
        },
        "norms" : false
      },
      "message": {
        "type": "text"
        # "index": true,                  # 是否允许搜索该字段，默认为 true
        # "norms": true,                  # 是否启用 norms
      }
    }
  }
  ```
  - norms ：给每个字段额外使用一个字节，存储多种有利于计算 score 的调节因子（normalization factors）。
    - text 字段默认启用 norms ，keyword 字段默认关闭 norms ，

#### 数据类型

文档中，字段名为字符串类型，而字段值的常见类型如下：
- 字符串 ：分为两种：
  - text
    - 适合全文搜索。
    - 适合存储非结构化数据，比如一篇文章。
    - ES 会将 text 字段解析之后再建立索引，比如字母转换为小写，删除标点符号、空白字符，分割成多个词语。\
      因此用 term 查询时会不匹配，应该用 match 查询。
  - keyword
    - 适合关键词搜索、排序、聚合。
    - 适合存储结构化数据，比如文章标题、编号。
- 数字 ：分为 integer、byte、float 等。
- 布尔值 ：boolean
- 日期 ：date
- 数组 ：array ，其中的所有元素必须采用相同的数据类型。
- 对象 ：即 JSON Object

### settings

：用于控制索引的存储等操作。
- settings 中的配置参数按修改类型分为两种：
  - dynamic ：支持在运行的索引上配置。
  - static ：只能在创建索引时配置，有的也支持在 closed 索引上配置。
    - `index.number_of_replicas` 属于动态配置，`index.number_of_shards` 属于静态配置。因此索引在创建之后，不能修改主分片数量。
- 例：
  ```sh
  "settings": {
    "index": {
      # "codec": "best_compression",  # 索引段的压缩率，默认为 LZ4 。更高的压缩率会减少占用的磁盘空间，但是增加读写文档的耗时
      "number_of_shards": 3,          # 主分片的数量，默认为 1 。该参数属于 static settings 。
      "number_of_replicas": 2,        # 每个主分片的副本数量，默认为 1
      "refresh_interval" : "5s",      # 每隔一定时间自动刷新一次索引。默认为 1 s ，接近实时搜索。设置成 -1 则不自动刷新
      "max_result_window": "10000",   # 限制单个请求搜索文档的最大数量
    },
    "blocks": {                       # 用于禁止对索引的一些操作
      "read": true,                   # 禁止读文档
      "write": true,                  # 禁止写文档
      "metadata": true,               # 禁止读写元数据
      "read_only": true,              # 禁止写文档、元数据
      "read_only_allow_delete": true, # 在 read_only 的基础上，允许删除索引（但依然不允许删除文档，因为它并不会释放磁盘空间）
    }
  }
  ```
  - 当主机的磁盘使用率超过 95% （默认）时，ES 会自动找出有 shard 存储在该主机上的所有索引，开启 read_only_allow_delete 。低于阈值时会自动解除限制。

### component template

：组件模板。可以被索引模板继承，从而实现更抽象化的模板。
- 例：创建一个组件模板
  ```sh
  PUT /_component_template/my_component_template
  {
    "template": {
      "mappings": {
        "properties": {
          "@timestamp": {
            "type": "date"
          }
        }
      }
    }
  }
  ```

## shard

- ES 的分片（shard）根据用途分为两种：
  - 主分片（primary shard）
    - ：用于存储某个索引的数据。
    - 支持读、写请求。
    - 每个索引可以划分 1 个或多个主分片。
  - 副分片（replica shard）
    - ：用作某个主分片的副本。
    - 只支持读请求，不支持写请求。
    - 每个主分片可以有 0 个或多个副分片。

### _split

- API 格式： `POST /<index>/_split/<target-index>` 。
- 用途：将一个索引分割为拥有更多主分片的新索引
- 例：
  ```sh
  POST /my-index-1/_split/my-index-2
  {
    "settings": {
      "index.number_of_shards": 2
    }
  }
  ```
- 分割索引的前提条件：
  - 源索引的 health 为 green 。
  - 源索引为只读。可使用以下配置：
    ```sh
    PUT /my-index-1/_settings
    {
      "settings": {
        "index.blocks.write": true    # 禁止写操作，但允许删除
      }
    }
    ```
  - 目标索引不存在。
  - 目标索引的主分片数，是源索引的主分片数，的整数倍。使得每个源索引的主分片，可以平均拆分成多个目标索引的主分片。
- 分割索引的工作流程：
  1. 创建目标索引，继承源索引的配置，但主分片数更多。
  2. 将源索引的数据通过硬链接或拷贝，迁移到目标索引。
  3. 允许目标索引被客户端访问。

### _shrink

- API 格式： `POST /<index>/_shrink/<target-index>` 。
- 用途：将一个索引收缩为拥有更少主分片的新索引。
- 例：
  ```sh
  POST /my-index-1/_shrink/my-index-2
  {
    "settings": {
      "index.number_of_shards": 1
    }
  }
  ```
- 收缩索引的前提条件：
  - 源索引的 health 为 green 。
  - 源索引为只读，并且所有主分片位于同一个节点上。可使用以下配置：
    ```sh
    PUT /my-index-1/_settings
    {
      "settings": {
        "index.number_of_replicas": 0,                        # 将主分片的副分片数量改为 0 ，方便迁移
        "index.routing.allocation.require._name": "node-1",   # 将主分片全部移到一个节点上
        "index.blocks.write": true
      }
    }
    ```
  - 目标索引不存在。
  - 源索引的主分片数，是目标索引的主分片数，的整数倍。

## segment

### API

- 相关 API ：
  ```sh
  POST  /<index>/_refresh       # 触发一次索引的 Refresh
  POST  /<index>/_flush         # 触发一次索引的 Flush

  POST  /_forcemerge                                    # 执行一次 segment 的强制合并
  POST  /<index>/_forcemerge?                           # 将指定的索引强制合并
                            only_expunge_deletes=true   # 只合并文档删除率超过 expunge_deletes_allowed 的 segment
                            max_num_segments=1          # 将每个 shard 中的 segment 合并到只剩几个，不管文档删除率
  GET   /_tasks?detailed=true&actions=*forcemerge       # 查看正在执行的 forcemerge 任务
  ```
  - 删除一个文档之后，如果没有 Refresh ，则依然可以查询到该文档，并且再请求删除该文档时会报错：`version conflict, current version [2] is different than the one provided [1]`
  - 发出 forcemerge 请求时：
    - 会阻塞客户端，直到合并完成才返回响应。
    - 如果客户端断开连接，则合并会在后台继续执行。
    - 如果客户端发出多个合并请求，则等前一个执行完了才会执行后一个。
    - 如果 forcemerge 请求没有加上 URL 参数，则也是按照自动合并的算法，只处理适合合并的 segment 。

- 请求 `GET /_cat/segments/test_segments?v` 的结果示例：
  ```sh
  index         shard prirep ip         segment   generation  docs.count  docs.deleted    size size.memory committed searchable version compound
  test_segments 0     p      10.0.0.1   _x                33        6665             0  15.4mb       74939 true      true       7.4.0   true
  test_segments 0     p      10.0.0.1   _12               38       13000             0    28mb       97976 true      true       7.4.0   true
  test_segments 0     p      10.0.0.1   _14               40       39416             0  78.6mb      178092 true      true       7.4.0   true
  ```
  表中每行描述一个 segment 的信息，各列的含义如下：
  ```sh
  index           # 该 segment 所属的索引
  shard           # 所属的分片
  prirep          # 分片类型，为 primary 或 replica
  ip              # 分片所在主机的 IP
  segment         # segment 在当前 shard 中的 36 进制编号，从 _0 开始递增。新增的文档会存储在编号最大的 segment 中，但合并之后，文档所在的 segment 可能变化
  generation      # generation 的十进制编号，从 0 开始递增

  docs.count      # 可见的文档数。这里将嵌套文档与父文档分别计数，但不包含 deleted 文档，不包含尚未 refresh 的文档
  docs.deleted    # deleted 文档数
  size            # 占用的磁盘空间，单位 bytes
  size.memory     # 占用的内存空间，单位 bytes
  committed       # 该 segment 是否已经提交到磁盘。取值为 false 则说明正在使用 translog
  searchable      # 该 segment 是否允许搜索

  version         # 存储该 segment 的 Lucene 版本
  compound        # 该 segment 的所有文件是否已经合并为一个文件。这样能减少打开的文件描述符，但是会占用更多内存，适合体积小于 100M 的 segment
  ```
  - `docs.count + docs.deleted` 等于实际存储的文档总数。
  - `docs.deleted / (docs.count + docs.deleted)` 等于文档删除率。

### 配置

- 索引中关于 Lucene segment 配置：
  ```sh
  PUT /my-index-1
  {
    "settings": {
      "index": {
        "translog": {
          "durability": "request",            # 当客户端发出写请求时，要等到将 translog 通过 fsync 写入磁盘之后，才返回响应
          "sync_interval": "5s",              # 每隔多久执行一次 fsync （不考虑是否有客户端请求）
          "flush_threshold_size": "512mb",    # 当 translog 超过该大小时，就执行一次 Flush
        }
        "merge": {
          "policy": {
            "expunge_deletes_allowed": 10,    # 调用 expungeDeletes 时，只合并文档删除率超过该值的 segment ，默认为 10%
            "floor_segment": "2mb",           # 自动合并时，总是合并小于该体积的 segment ，不管文档删除率。这样能避免存在大量体积过小的 segment
            "max_merged_segment": "5gb",      # 自动合并时，限制产生的 segment 的最大大小
            "max_merge_at_once": 10,          # 自动合并时，每次最多同时合并多少个 segment
            "max_merge_at_once_explicit": 30, # forcemerge 或 expunge_delete 时，每次最多同时合并多少个 segment
            "segments_per_tier": 10,          # 每层最多存在的 segment 数，如果超过该值则触发一次自动合并
          }
        }
      }
    }
  }
  ```
- 对于 max_merged_segment ：
  - 如果 n 个 segment 预计的合并后体积低于 max_merged_segment ，则自动合并。否则，让 n-1 再预计合并后体积。
    - 即使 n=1 ，但如果存在 deleted 文档，也可能被自动合并。
  - 如果某个 segment 的体积超过 max_merged_segment ，则可能一直不会被自动合并，除非其中的文档删除率足够大。
    - 此时可以通过 forcemerge 强制合并，或者通过 reindex 重新创建该索引。

## data stream

：数据流。一种管理单元，包含一个或多个后端索引（backing index）。
- 数据流适合存储大量呈时间序列的数据，且平时只需要新增文档，很少修改、删除文档。
- 数据流创建的索引默认按以下格式命名：
  ```sh
  ds-<data-stream>-<yyyy.MM.dd>-<generation_id>
  ```
- 当数据流收到一个查询文档的请求时，会自动路由到它的各个索引。
- 每个存储到数据流的文档，必须包含一个 `@timestamp` 字段，属于 date 或 date_nanos 类型。
- 例：向一个数据流中新增一个文档
  ```sh
  POST /my-data-stream/_doc/
  {
    "@timestamp": "2020-03-08T11:06:07.000Z",
    "message": "Hello"
  }
  ```
  查询数据流中的文档：
  ```sh
  GET /my-data-stream/_search
  {
    "query": {
      "match": {
        "message": "Hello"
      }
    }
  }
  ```

## ILM

：索引生命周期管理（Index lifecycle Management），是一些自动管理索引的策略，比如减少副本的数量、超过多少天就删除索引。

## 相关 API

### _cat

- ES 返回的响应内容默认采用 JSON 格式，适合处理详细信息。而使用 _cat API 会按列表形式返回一些简单的统计信息，更适合供人阅读。
- 相关 API ：
  ```sh
  GET  /_cat/nodes?v            # 查询节点的信息

  GET  /_cat/indices?v          # 查询索引的信息
  GET  /_cat/indices/<index>?v

  GET  /_cat/shards?v           # 查询分片的信息
  GET  /_cat/shards/<index>?v

  GET  /_cat/segments?v         # 查询索引段的信息
  GET  /_cat/segments/<index>?v

  GET  /_cat/templates?v        # 查询索引模板的信息
  ```
  - 在 URL 末尾加上 `?v` ，则会在列表头部增加显示一行表头。

- 例：查询所有节点的信息
  ```sh
  [root@Centos ~]# curl 127.0.0.1:9200/_cat/nodes?v
  ip         heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
  10.0.0.1             11          85   1    0.06    0.09     0.18 dilm      *      node-1
  ```

- 例：查询所有分片
  ```sh
  [root@Centos ~]# curl 127.0.0.1:9200/_cat/indices?v
  health status index   uuid                   pri rep docs.count docs.deleted store.size pri.store.size
  yellow open   class   aeUT1h6QS8-vSAzoEclR3Q   1   1          0            0       283b           283b
  yellow open   student EaDptPz9TtqGk-CNL-yTMg   1   1          1            0      4.4kb          4.4kb
  ```
  - health 表示集群的分片状态，status 表示索引是否被关闭。
  - 这里索引的 health 为 yellow ，是因为只部署了单实例 ES ，而副分片不能被分配到主分片所在节点上，导致一直处于未分配状态。

### _tasks

- _tasks API 用于管理 ES 集群中执行的任务。
- 相关 API ：
  ```sh
  GET   /_tasks                       # 查询各个节点上正在执行的任务
  GET   /_tasks?detailed=true         # 查询任务的详细信息
  GET   /_tasks?nodes=node1,node2     # 查询指定节点上执行的任务
  GET   /_tasks?wait_for_completion=true&timeout=10s  # 等待任务执行完，才返回响应

  POST  /_tasks/<task_name>/_cancel         # 取消任务
  POST  /_tasks/_cancel?nodes=node1,node2   # 取消任务
  ```

### _reindex

- reindex API 用于将源 index 中的文档拷贝到目标 index 中。
  - 源 index 可以是位于当前 ES ，也可以是位于其它 ES 。
  - 拷贝时，不会拷贝 settings、mappings ，因此需要创建目标 index 或 index template 。
- 例：
  ```sh
  POST /_reindex
  {
    "source": {
      "index": "index_1",
      # "query": {            # 可以加上 query 子句，只拷贝部分文档
      #   "match": {
      #     "test": "data"
      #   }
      # },
      # "max_docs": 1000,     # 限制拷贝的文档数，默认不限制
    },
    "dest": {
      "index": "index_2",
      # "op_type": "create"
    },
    # "conflicts": "proceed"  # 拷贝时，如果遇到文档已存在的 version conflict 报错，默认会停止 reindex 。如果设置该参数，则会继续执行 reindex ，只是记录冲突的次数
  }
  ```

- 例：从其它 ES 拷贝文档到当前 ES
  1. 在 elasticsearch.yml 中添加允许 reindex 的远程 ES 白名单：
      ```yml
      reindex.remote.whitelist: "10.0.0.2:9200,10.0.1.*:*"   # 可以填多个服务器地址，不需要加 http:// 前缀
      ```
  2. 调用 reindex API ：
      ```sh
      POST /_reindex
      {
        "source": {
          "remote": {                       # 要连接的远程 ES
            "host": "http://10.0.0.2:9200", # ES 的地址必须加协议前缀，且声明端口号
            "username": "test",
            "password": "******"
          },
          "index": "index_1",               # 要拷贝的源 index 名称
        },
        "dest": {
          "index": "index_2"
        }
      }
      ```
  3. 查看 reindex 任务的进度：
      ```sh
      GET /_tasks?detailed=true&actions=*reindex
      ```

### _rollover

- 过渡（rollover）：当满足指定条件时，将索引迁移到另一个索引。
- 相关 API ：
  ```sh
  POST /<rollover-target>/_rollover/<target-index>  <request_body>  # 给索引添加一个过渡规则
  ```
  - 过渡目标 target-index 可以是索引别名或数据流。如果省略该值，则将原索引名递增 1 ，作为目标名。
- 例：
  ```sh
  POST /my-index-1/_rollover/my-index-2
  {
    "conditions": {                       # 这里指定了多个条件，只要满足其中之一即可
      "max_age":   "7d",                  # 索引创建之后的存在时长
      "max_docs":  1000,
      "max_size": "5gb"
    }
  }
  ```
