# 部署

ES 常见的部署架构：
- 单实例
- 集群
  - 由多个实例组成分布式集群，获得更大的容量、更高的性能，还可通过冗余节点提高可用性。
- 远程集群
  - 远程集群与本地集群之间独立工作，但可以查询、拷贝其数据，实现横向扩容。

## 单实例

### 部署

- 下载二进制版：
  ```sh
  wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.0-linux-x86_64.tar.gz
  ```
  解压后运行 ES 服务器：
  ```sh
  bin/elasticsearch       # 在前台运行
                    -d    # 以 daemon 方式运行
  ```
  运行时需要 JDK 环境，不过二进制发行版自带了一个 JDK 。

- 或者用 Docker 部署：
  ```sh
  docker run -d --name elasticsearch \
             --network host \   # 使用宿主机的网卡，以便绑定宿主机的对外 IP
             -e "discovery.type=single-node" \
             elasticsearch:7.10.0
  ```

### 配置

ES 服务器的配置文件是 `config/elasticsearch.yml` ，内容示例如下：
```yml
cluster.name: cluster-1           # 该 ES 所属的集群名
node.name: node-1                 # 该 ES 的节点名，默认为当前主机名

network.host: 10.0.0.1            # 该 ES 绑定的 IP 。该 IP 会公布给集群中其它 ES ，供它们访问
http.port: 9200                   # HTTP 通信监听的端口，供用户访问
transport.port: 9300              # TCP 通信监听的端口，供集群中其它 ES 节点访问

path.data: /var/data/elasticsearch
path.logs: /var/log/elasticsearch
```

### 运行环境

ES 启动时会检查以下环境条件是否满足，如果不满足则会发出警告。如果此时还配置了 `network.host` 参数，则 ES 会按生产环境严格要求，将这些警告升级为异常。
- 禁用 Swap 分区：
  - 需要执行命令 `swapoff -a` ，并且将 `/etc/fstab` 文件中的 swap 分区都注释。
- 增加进程虚拟内存的上限：
  - 需要执行命令 `sysctl vm.max_map_count=262144` ，并在 `/etc/sysctl.conf` 文件中永久修改该参数。
- 增加进程数量的上限：
  - 需要执行命令 `ulimit -u 4096` ，并在 `/etc/security/limits.conf` 文件中永久修改该参数。
- 增加文件描述符数量的上限：
  - 需要执行命令 `ulimit -n 65535` ，并在 `/etc/security/limits.conf` 文件中永久修改该参数。

## 集群

### 节点

- 一个 ES 集群（cluster）中的每个 ES 实例称为一个节点（node）。
- 集群中有且仅有一个主节点，负责管理集群，比如增删索引、分配分片给节点。

- 一个 ES 节点可以担任多种角色：
  - `master`
    - ：主资格节点（master-eligible），有资格被选为主节点。
    - 只有主资格节点可以参与主节点的选举投票。
  - `data`
    - ：数据节点，负责存储数据，支持增删查改、聚合等操作。
    - master 和 data 节点都需要使用 `path.data` 目录。
  - `ingest`
    - ：摄取节点，负责将管道应用于文档，以便在建立索引之前加工文档。
  - `ml`
    - ：机器学习节点。集群至少拥有一个此类节点才能提供机器学习功能。
  - `remote_cluster_client`
    - ：远程集群节点，可以连接到远程集群，作为其客户端。
  - `transform`
    - ：转换节点。提供转换功能。
  - `coordinating`
    - ：协调节点。它是每个节点的隐式角色，不能取消。
    - 每个节点都知道各个文档存储在哪个节点上，也默认可以处理用户的 HTTP 请求。\
      因此用户可以向任意节点发出查询请求，该节点会将请求转发给存储相应文档的数据节点（可能有多个），然后将查询结果返回给用户。

- 节点的默认角色配置如下：
  ```yml
  node.master: true
  node.voting_only: false   # 是否只参与主节点选举，而不担任主节点
  node.data: true
  node.ingest: true
  node.ml: true
  cluster.remote.connect: true
  ```

- 在以下情况下，主资格节点会发起主节点的选举：
  - 发现它自己不是主节点。
  - 询问其它节点，发现大家都没有连接到主节点。
  - 发现有至少 `discovery.zen.minimum_master_nodes` 个主资格节点没有连接到主节点。
    该参数的默认值为：` 主资格节点总数/2 + 1 `

- ES 集群的高可用方案：
  - 部署至少 3 个主资格节点，其中至少 2 个节点为 `node.voting_only: false` ，从而可以通过选举更换主节点。
  - 不能同时停止 50% 数量的主资格节点，否则集群会不能投票决策。但可以分多次停止。
  - 让每个节点专注于一种角色，以减少不相关的工作负担。比如配置专用的主节点：
    ```yml
    node.master: true
    node.voting_only: false
    node.data: false
    node.ingest: false
    node.ml: false
    cluster.remote.connect: false
    ```

### 分片

- ES 会将每个新增的索引划分成多个分片（shard），该索引下新增的文档会平均分配到各个分片中，而所有分片会分散存储到各个节点中。
  - 分片是 ES 存储数据的最小单位。
  - 当集群扩容或缩容时，ES 会自动迁移分片，均衡地存储到各个节点。
  - 单个分片的存储容量理论上没有上限，但是存储的文档越多，会导致查询耗时越久。
  - 当用户查询某个文档时，ES 会先找到存储该文档的分片，然后读取该文档的内容，返回给用户。

- 分片分为两类：
  - 主分片（primary shard）
    - ：用于存储某个索引的数据。
    - 每个索引可以划分 1 个或多个主分片。
  - 副分片（replica shard）
    - ：主分片的副本，只支持读请求，不支持写请求。
    - 每个主分片可以有 0 个或任意个副分片。

### 分片数

- 索引在创建之后，可以修改配置中的副分片数量，但不能修改主分片数量。
- 可以将一个索引分割为拥有更多主分片的新索引：
  ```sh
  POST /my-index-1/_split/my-index-2
  {
    "settings": {
      "index.number_of_shards": 2
    }
  }
  ```
  - API 为 `POST /<index>/_split/<target-index>` 。
  - 分割索引的前提条件：
    - 源索引的 health 为 green 。
    - 源索引为只读。可使用以下配置：
      ```sh
      PUT /my-index-1/_settings
      {
        "settings": {
          "index.blocks.write": true    # 禁止写操作，但允许删除
        }
      }
      ```
    - 目标索引不存在。
    - 目标索引的主分片数，是源索引的主分片数，的整数倍。使得每个源索引的主分片，可以平均拆分成多个目标索引的主分片。
  - 分割索引的工作流程：
    1. 创建目标索引，继承源索引的配置，但主分片数更多。
    2. 将源索引的数据通过硬链接或拷贝，迁移到目标索引。
    3. 允许目标索引被用户访问。

- 可以将一个索引收缩为拥有更少主分片的新索引：
  ```sh
  POST /my-index-1/_shrink/my-index-2
  {
    "settings": {
      "index.number_of_shards": 1
    }
  }
  ```
  - API 为 `POST /<index>/_shrink/<target-index>` 。
  - 收缩索引的前提条件：
    - 源索引的 health 为 green 。
    - 源索引为只读，并且所有主分片位于同一个节点上。可使用以下配置：
      ```sh
      PUT /my-index-1/_settings
      {
        "settings": {
          "index.number_of_replicas": 0,                        # 将主分片的副分片数量改为 0 ，方便迁移
          "index.routing.allocation.require._name": "node-1",   # 将主分片全部移到一个节点上
          "index.blocks.write": true
        }
      }
      ```
    - 目标索引不存在。
    - 源索引的主分片数，是目标索引的主分片数，的整数倍。

### 配置

- 部署 ES 集群时，只需要分别部署多个 ES 实例，然后在它们的配置文件中加入如下配置：
  ```yml
  network.host: 10.0.0.1  # 当前节点的对外 IP ，供其它节点访问

  discovery.seed_hosts:   # 声明该集群的所有节点，默认值为 127.0.0.1、[::1]
    - 10.0.0.1:9300
    - 10.0.0.2:9300
    - 10.0.0.3:9300
  ```
  - ES 服务器启动之后，会自动检查这些节点，如果存在其它 ES 服务器，并且拥有相同的集群名，则组成同一个集群。

- 如果是部署一个新集群，还需要声明初始的主资格节点：
  ```yml
  cluster.initial_master_nodes:
    - node-1              # 这里使用节点名，不使用 IP
    - node-2
    - node-3
  ```

### 管理

- 相关 API ：
  ```sh
  GET   /_cluster/stats     # 查询集群的统计信息
  GET   /_cluster/health    # 查询集群的健康状态
  GET   /_cluster/settings  # 查询集群的配置
  
  GET   /_nodes             # 查询所有节点的详细信息
  GET   /_nodes/<node>      # 查询指定节点的详细信息，可以指定节点名、节点 IP 等
  ```

- 例：查询 ES 集群的健康状态
  ```sh
  [root@Centos ~]# curl -X GET 127.0.0.1:9200/_cluster/health?pretty
  {
    "cluster_name" : "cluster-1",
    "status" : "yellow",            # 集群的状态
    "timed_out" : false,
    "number_of_nodes" : 1,          # 节点的数量
    "number_of_data_nodes" : 1,     # 数据节点的数量
    "active_primary_shards" : 4,    # 主分片的数量
    "active_shards" : 4,            # 分片的数量
    "relocating_shards" : 0,
    "initializing_shards" : 0,
    "unassigned_shards" : 4,        # 未分配的分片的数量
    "delayed_unassigned_shards" : 0,
    "number_of_pending_tasks" : 0,
    "number_of_in_flight_fetch" : 0,
    "task_max_waiting_in_queue_millis" : 0,
    "active_shards_percent_as_number" : 50.0
  }
  ```
  - status 的可能取值：
    - `green` ：所有主分片、副分片都可用。
    - `yellow` ：所有主分片都可用，但存在不可用的副分片。
    - `red` ：存在不可用的主分片。
  - 副分片不能被分配到主分片所在节点上，因为那样不能实现灾备。如果集群内没有其它节点了，副分片就会一直处于未分配状态。

## 远程集群

- ES 支持给本地集群添加多个远程集群（remote cluster）。
  - 这些集群之间会独立工作，独立存储自己的数据。
  - 这是单向连接，本地集群故障时不会影响远程集群，但远程集群故障时可能影响本地集群。
- 用户可以跨集群搜索，同时查询本地集群和远程集群，从而实现 ES 的横向扩容。
  - 原理：
    1. 用户将跨集群的查询请求发送到本地集群。
    2. 本地集群验证用户的身份，如果有效，则将请求及用户的身份转发到远程集群。
    3. 远程集群验证用户的身份，如果有权访问指定的数据，则执行查询，然后将查询结果返回给本地集群。
    4. 本地集群将远程集群的查询结果返回给用户。
  - 本地集群使用的 SSL 公钥必须受到远程集群的信任。
  - 用户账号必须在本地集群、远程集群都存在。

### 配置

- 可以在 elasticsearch.yml 文件中配置远程集群，但这只会对当前节点生效。如下：
  ```yml
  cluster:
      remote:
          cluster_1:                                    # 添加一个远程集群，该名称不必与目标集群的实际名称一致
              seeds:
                - 10.0.0.1:9300                         # 远程集群中的节点列表
          cluster_2:                                    # 添加另一个远程集群
              seeds:
                - 10.0.0.2:9300
              # transport.initial_connect_timeout: 30s  # 启动当前节点时，第一次连接到远程集群的超时时间
              # transport.ping_schedule: 30s            # 每隔多久检查与远程集群的连接是否正常正常，默认为 -1 ，即不检查
              # transport.compress: true                # 将请求压缩之后再发送到远程集群
              # skip_unavailable: false                 # 跨集群搜索时是否跳过不可用集群
  ```

- 也可以通过 HTTP 请求添加远程集群，上传其配置信息：
  ```sh
  PUT _cluster/settings
  {
      "persistent": {
          "cluster": {
              "remote": {
                  "cluster_1": {
                      "seeds": [                        # 设置 "seeds": null 则会删除该远程集群
                          "127.0.0.1:9300"
                      ]
                  },
                  "cluster_2": {
                      "seeds": [
                          "10.0.0.2:9300"
                      ]
                  }
              }
          }
      }
  }
  ```

- 相关 API ：
  ```sh
  GET   /_cluster/settings    # 查询集群的配置，包括远程集群
  GET   /_remote/info         # 查询远程集群的状态
  ```

### 用法

- 使用 `集群名:索引名` 的方式即可跨集群查询：
  ```sh
  GET /student/_search                # 不指定集群名，则默认查询本地集群
  GET /cluster_1:student/_search      # 可以指定一个集群进行查询
  GET /student,cluster_1:student,cluster_2:student/_search    # 可以指定多个集群进行查询
  ```

- 可以创建指向远程集群的索引模式：
  ```sh
  cluster_1:student
  ```

- 可以通过 reinex 功能将远程集群的数据拷贝到本地集群。

