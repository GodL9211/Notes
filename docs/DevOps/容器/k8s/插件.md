# 插件

## API

k8s 为一些底层组件定义了 API 规范，如果一个插件实现了这些 API ，则可以替换默认组件。比如：
- 容器运行时接口（Container Runtime Interface ，CRI）：供 k8s 调用容器运行时，从而管理容器、镜像。
  - 大部分容器运行时并不兼容 CRI ，因此 k8s 还开发了一些 shim 模块，用于将各种容器运行时对接到 CRI 。
    - 后来改为通过 containerd 或 CRI-O 来调用底层的容器运行时。
  - CRI 使得 k8s 与容器运行时解耦，允许 k8s 同时使用多种容器运行时。
- 容器网络接口（Container Network Interface ，CNI）：供 k8s 管理容器的网络。
- 容器存储接口（Container Storage Interface ，CSI）：供 k8s 管理容器的存储层。
  - k8s 本身提供了 hostPath、ConfigMap 等类型的 volume 。而一些第三方的存储程序可通过 CSI 接口接入 k8s 集群，提供一些其它类型的 volume 。

常见插件：
- kube-dns ：为 k8s 集群提供 DNS 服务。
- Kube-router
- Flannel ：一个 CNI 插件，比较简单。
- Calico ：一个 CNI 插件，比较复杂，功能更多。
- Dashboard ：提供 Web UI 。
- Federation ：提供跨可用区的集群。
  - k8s 原本是部署在同一局域网内的主机上，如果部署在跨地域（Region）的不同主机上，则网络延迟会比较大。
- Fluentd-elasticsearch ：采集、管理 k8s 集群的日志。



## Helm

：一个命令行工具，用于管理 k8s 中的应用，相当于高层的包管理工具。
- 将 k8s 中一个应用的相关配置文件打包成一个 .tgz 文件，称为 Chart 。
  - charts 可以存储在本机，或者存储到远端仓库。
- Helm 2.0 采用 C/S 架构。
  - 客户端名为 Helm ，负责管理 charts 。
  - 服务器名为 Tiller ，会将客户端发来的 chart 渲染成 release 文件，然后传给 k8s 的 apiserver 。
- Helm 3.0 于 2019 年 11 月发布，与 Helm2 不兼容，移除了 Tiller ，成为了一个纯客户端工具。

命令：
```sh
helm
    init            # 初始化 Helm（这会创建 Helm 的配置文件、安装 Tiller）
    reset           # 卸载 Tiller

    create <dir>    # 创建一个 Chart 目录（会包含一些模板文件）
    inspect <dir>   # 查看一个 Chart 的详细信息
    lint <dir>      # 检查 Chart 的语法
    package <dir>   # 将一个 Chart 目录打包，这会生成一个 .tgz 文件
    template <dir>                       # 渲染 Chart 目录中的所有模板
            > release.yml                # 将渲染结果保存到一个文件中
            -x templates/configmap.yaml  # 只渲染指定模板文件

    install <name>  # 将一个 Chart 部署到 k8s
    delete <name>   # 删除 k8s 中的一个 release
    status <name>   # 显示 k8s 中的一个 release 的状态
    list            # 显示 k8s 中的所有 release

    search <name>   # 在 Helm Hub 中查找 Chart
```

### 制作 Chart

Chart 的目录结构：
```sh
app/
├── Chart.yaml          # 描述该 Chart 的信息
├── templates/          # 存放该应用的配置文件
│   ├── deployment.yaml
│   └── service.yaml
├── values.yaml         # 用于给 templates 中的变量赋值
├── requirements.yaml   # 描述当前 Chart 依赖的其它 Chart
├── charts/             # 存放当前 Chart 依赖的其它 Chart
├── .helmignore         # 描述打包 Chart 时要忽略的文件
├── LICENSE
└── README.md
```

Chart.yaml 的示例：
```yaml
apiVersion: v1
appVersion: "1.0"
description: A Helm chart for Kubernetes
name: redis
version: 0.1.0
```

values.yaml 的示例：
```yaml
image:
  repository: myharbor.com/test/redis
  tag: 5.0.6
```

在 deployment.yaml 中使用 values 的示例：
```yaml
template:
  spec:
      containers:
      - image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
      ...
```

## Istio

：一个 Service Mesh 框架。
- [官方文档](https://istio.io/latest/docs/)
- 发音为 `/iss-tee-oh/` 。
- 原生的 k8s 缺乏管理 Pod 流量的能力，而 Istio 提供了服务发现、负载均衡、动态路由、熔断、可观测性等功能，更擅长部署微服务系统。

### 原理

- Istio 系统包含以下组件：
  - envoy ：一个代理软件，担任数据平面（data plane）。
    - 在 k8s Pod 中添加一个 init 类型的容器，名为 istio-init 。负责设置 iptables 规则，将服务的出入流量转发到 Envoy 。
    - 在 k8s Pod 中添加一个 sidecar 类型的容器，名为 istio-proxy 。负责运行 envoy 和 pilot-agent ，以透明代理的方式转发当前 Pod 收发的网络包。
  - istiod ：担任控制平面（control plane），包含以下组件：
    - pilot ：负责配置、引导启动 envoy 。
    - citadel ：负责颁发证书、轮换证书。
    - galley ：负责管理、分发 Istio 的配置。
  - ingressGateways ：负责管理 k8s 集群接收的网络包。
  - egressGateways ：负责管理 k8s 集群发出的网络包。
  <!-- - operator ：供用户管理 Istio 。 -->
  - istioctl ：命令行客户端。
  - kiali ：提供了对 Istio 的 Web 管理页面。还支持显示流量图表、链路追踪，此时采用 Prometheus、jaeger 作为数据源。
  - jaeger ：一个 Web 服务器，用于链路追踪。可以不安装。

<!--
不会管理 DaemonSet 类型的 Pod ？
 -->

### 部署

1. 查看 Istio 的 [兼容列表](https://istio.io/latest/docs/releases/supported-releases/#support-status-of-istio-releases) ，找到与当前 k8s 版本兼容的 Istio 版本。然后下载：
    ```sh
    VERSION=1.13.9
    wget https://github.com/istio/istio/releases/download/$VERSION/istio-$VERSION-linux-amd64.tar.gz
    tar -xf istio-$VERSION-linux-amd64.tar.gz
    cp istio-$VERSION/bin/istioctl /usr/bin/istioctl
    chmod +x /usr/bin/istioctl
    ```
2. 安装 Istio ：
    ```sh
    export KUBECONFIG=/root/.kube/config
    istioctl install --set profile=demo -y      # 采用 demo 配置来安装，这会启用 istiod、ingressGateways、egressGateways
    # istioctl install --set profile=default -y # 采用 default 配置来安装，这不会启用 egressGateways ，减少开销
    ```
    - 这会在 k8s 中创建一个 istio-system 命名空间，以 Deployment 方式部署 istiod 等应用。
    - 卸载 Istio 的命令：
      ```sh
      istioctl uninstall --purge
      kubectl delete namespace istio-system
      ```

3. 安装 kiali 套件：
    ```sh
    kubectl apply -f istio-$VERSION/samples/addons/kiali.yaml
    kubectl apply -f istio-$VERSION/samples/addons/jaeger.yaml
    kubectl apply -f istio-$VERSION/samples/addons/prometheus.yaml
    kubectl apply -f istio-$VERSION/samples/addons/grafana.yaml
    ```
    - 需要在 kiali 的配置文件里指定依赖组件的地址：
      ```yml
      external_services:
        custom_dashboards:
          enabled: true
        istio:
          root_namespace: istio-system
        tracing:
          enabled: true
          in_cluster_url: http://tracing:16685/jaeger
          use_grpc: true
        prometheus:
          url: http://prometheus:9090/
        grafana:
          enabled: true
          in_cluster_url: http://grafana:3000/
      ```

4. 如下，给一个 k8s 命名空间添加 label ，指示 istio 管理该命名空间。这样以后新建每个 Pod 时会自动添加 istio sidebar 。
    ```sh
    kubectl label namespace default istio-injection=enabled
    ```
