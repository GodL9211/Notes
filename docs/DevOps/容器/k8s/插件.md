# 插件

## API

k8s 为一些底层组件定义了 API 规范，如果一个插件实现了这些 API ，则可以替换默认组件。比如：
- 容器运行时接口（Container Runtime Interface ，CRI）：供 k8s 调用容器运行时，从而管理容器、镜像。
  - 大部分容器运行时并不兼容 CRI ，因此 k8s 还开发了一些 shim 模块，用于将各种容器运行时对接到 CRI 。
    - 后来改为通过 containerd 或 CRI-O 来调用底层的容器运行时。
  - CRI 使得 k8s 与容器运行时解耦，允许 k8s 同时使用多种容器运行时。
- 容器网络接口（Container Network Interface ，CNI）：供 k8s 管理容器的网络。
- 容器存储接口（Container Storage Interface ，CSI）：供 k8s 管理容器的存储层。
  - k8s 本身提供了 hostPath、ConfigMap 等类型的 volume 。而一些第三方的存储程序可通过 CSI 接口接入 k8s 集群，提供一些其它类型的 volume 。

常见插件：
- kube-dns ：为 k8s 集群提供 DNS 服务。
- Kube-router
- Flannel ：一个 CNI 插件，比较简单。
- Calico ：一个 CNI 插件，比较复杂，功能更多。
- Dashboard ：提供 Web UI 。
- Federation ：提供跨可用区的集群。
  - k8s 原本是部署在同一局域网内的主机上，如果部署在跨地域（Region）的不同主机上，则网络延迟会比较大。
- Fluentd-elasticsearch ：采集、管理 k8s 集群的日志。



## Helm

：一个命令行工具，用于管理 k8s 中的应用，相当于高层的包管理工具。
- 将 k8s 中一个应用的相关配置文件打包成一个 .tgz 文件，称为 Chart 。
  - charts 可以存储在本机，或者存储到远端仓库。
- Helm 2.0 采用 C/S 架构。
  - 客户端名为 Helm ，负责管理 charts 。
  - 服务器名为 Tiller ，会将客户端发来的 chart 渲染成 release 文件，然后传给 k8s 的 apiserver 。
- Helm 3.0 于 2019 年 11 月发布，与 Helm2 不兼容，移除了 Tiller ，成为了一个纯客户端工具。

命令：
```sh
helm
    init            # 初始化 Helm（这会创建 Helm 的配置文件、安装 Tiller）
    reset           # 卸载 Tiller

    create <dir>    # 创建一个 Chart 目录（会包含一些模板文件）
    inspect <dir>   # 查看一个 Chart 的详细信息
    lint <dir>      # 检查 Chart 的语法
    package <dir>   # 将一个 Chart 目录打包，这会生成一个 .tgz 文件
    template <dir>                       # 渲染 Chart 目录中的所有模板
            > release.yml                # 将渲染结果保存到一个文件中
            -x templates/configmap.yaml  # 只渲染指定模板文件

    install <name>  # 将一个 Chart 部署到 k8s
    delete <name>   # 删除 k8s 中的一个 release
    status <name>   # 显示 k8s 中的一个 release 的状态
    list            # 显示 k8s 中的所有 release

    search <name>   # 在 Helm Hub 中查找 Chart
```

### 制作 Chart

Chart 的目录结构：
```sh
app/
├── Chart.yaml          # 描述该 Chart 的信息
├── templates/          # 存放该应用的配置文件
│   ├── deployment.yaml
│   └── service.yaml
├── values.yaml         # 用于给 templates 中的变量赋值
├── requirements.yaml   # 描述当前 Chart 依赖的其它 Chart
├── charts/             # 存放当前 Chart 依赖的其它 Chart
├── .helmignore         # 描述打包 Chart 时要忽略的文件
├── LICENSE
└── README.md
```

Chart.yaml 的示例：
```yaml
apiVersion: v1
appVersion: "1.0"
description: A Helm chart for Kubernetes
name: redis
version: 0.1.0
```

values.yaml 的示例：
```yaml
image:
  repository: myharbor.com/test/redis
  tag: 5.0.6
```

在 deployment.yaml 中使用 values 的示例：
```yaml
template:
  spec:
      containers:
      - image: "{{ .Values.image.repository }}:{{ .Values.image.tag }}"
      ...
```

## Istio

：一个 Service Mesh 框架，通常部署在 k8s 集群中。
- [官方文档](https://istio.io/latest/docs/)
- 发音为 `/iss-tee-oh/` 。
- 原生的 k8s 缺乏管理 Pod 流量的能力，而 Istio 提供了服务发现、负载均衡、动态路由、熔断、可观测性等功能，更擅长微服务架构。

### 原理

- Istio 系统包含以下组件：
  - envoy ：一个代理软件，担任数据平面（data plane）。
    - 在 k8s Pod 中添加一个 init 类型的容器，名为 istio-init 。负责设置 iptables 规则，将服务的出入流量转发到 Envoy 。
    - 在 k8s Pod 中添加一个 sidecar 类型的容器，名为 istio-proxy 。负责运行 envoy 和 pilot-agent ，以透明代理的方式转发当前 Pod 收发的网络包。
  - istiod ：担任控制平面（control plane），包含以下组件：
    - pilot ：负责配置、引导启动 envoy 。
    - citadel ：负责颁发证书、轮换证书。
    - galley ：负责管理、分发 Istio 的配置。
  - ingressGateways ：负责管理 k8s 集群接收的网络包。
  - egressGateways ：负责管理 k8s 集群发出的网络包。
  <!-- - operator ：供用户管理 Istio 。 -->
  - istioctl ：命令行客户端。
  - kiali ：提供了对 Istio 的 Web 管理页面。还支持显示流量图表、链路追踪，此时采用 Prometheus、jaeger 作为数据源。
  - jaeger ：一个 Web 服务器，用于链路追踪。可以不安装。

<!--
不会管理 DaemonSet 类型的 Pod ？
 -->

- k8s 集群安装了 Istio 之后，可使用附带的 Istio Ingress 暴露服务到 k8s 集群外，也可使用 APISIX 等其它类型的 Ingress 。
  - 虽然这样访问 Pod 的流量要经过多层代理转发，但一般只增加了几毫秒耗时。

### 部署

1. 查看 Istio 的 [兼容列表](https://istio.io/latest/docs/releases/supported-releases/#support-status-of-istio-releases) ，找到与当前 k8s 版本兼容的 Istio 版本。然后下载：
    ```sh
    VERSION=1.13.9
    wget https://github.com/istio/istio/releases/download/$VERSION/istio-$VERSION-linux-amd64.tar.gz
    tar -xf istio-$VERSION-linux-amd64.tar.gz
    cp istio-$VERSION/bin/istioctl /usr/bin/istioctl
    chmod +x /usr/bin/istioctl
    ```
2. 安装 Istio ：
    ```sh
    export KUBECONFIG=/root/.kube/config
    istioctl install --set profile=demo -y      # 采用 demo 配置来安装，这会启用 istiod、ingressGateways、egressGateways
    # istioctl install --set profile=default -y # 采用 default 配置来安装，这不会启用 egressGateways ，减少开销
    ```
    - 这会在 k8s 中创建一个 istio-system 命名空间，以 Deployment 方式部署 istiod 等应用。
    - 卸载 Istio 的命令：
      ```sh
      istioctl uninstall --purge
      kubectl delete namespace istio-system
      ```

3. 安装 kiali 套件：
    ```sh
    kubectl apply -f istio-$VERSION/samples/addons/kiali.yaml
    kubectl apply -f istio-$VERSION/samples/addons/jaeger.yaml
    kubectl apply -f istio-$VERSION/samples/addons/prometheus.yaml
    kubectl apply -f istio-$VERSION/samples/addons/grafana.yaml
    ```
    - 需要在 kiali 的配置文件里指定依赖组件的地址：
      ```yml
      external_services:
        custom_dashboards:
          enabled: true
        istio:
          root_namespace: istio-system
        tracing:
          enabled: true
          in_cluster_url: http://tracing:16685/jaeger
          use_grpc: true
        prometheus:
          url: http://prometheus:9090/
        grafana:
          enabled: true
          in_cluster_url: http://grafana:3000/
      ```

4. 如下，给一个 k8s 命名空间添加 label ，指示 istio 管理该命名空间。这样以后新建每个 Pod 时会自动添加 istio sidebar 。
    ```sh
    kubectl label namespace default istio-injection=enabled
    ```

### 用法

#### Virtual Service

- 原理：
  - Istio 会利用 k8s 的服务发现机制，自动发现所有 Service、EndPoints 。
    <!-- 访问 Service IP 时，Istio 会取代 k8s 来实现反向代理？ -->
    - 一个 Service 有多个 EndPoints 时，Istio 默认采用轮询算法来分配流量，实现负载均衡。

- 虚拟服务（Virtual Service）
  - ： Istio 提供的一种 k8s 对象，用于配置路由规则，将某请求流量路由到某 upstream 。
  - k8s 原生的 Service 不支持配置路由规则，会将流量均匀分配给每个 EndPoints 。而 VirtualService 提供了复杂的路由规则。
  - 详细配置见 [官方文档](https://istio.io/latest/docs/reference/config/networking/virtual-service/)

- 例：根据 HTTP 请求的 uri 取值，路由到不同 upstream
  ```yml
  apiVersion: networking.istio.io/v1alpha3
  kind: VirtualService
  metadata:
    name: test-route
  spec:
    hosts:              # 如果请求流量的目标地址匹配该 hosts 数组，则采用该 VirtualService 的路由规则
    - 10.0.0.1          # 该数组中的 host 不必是一个实际可访问的地址。格式可以是 IP 地址、DNS 名称，还可以使用通配符 *
    - test.com
    - nginx.default     # k8s 创建的 DNS 名称可以用 FQDN 格式，或短域名。如果省略命名空间，则会在 VirtualService 所在命名空间寻址
    - *
    # gateways:         # 当请求流量来自该网关时，才采用该 VirtualService
    # - ingress-gateway
    http:               # 如果请求流量是 HTTP 报文，且 headers 包含 username: test ，则路由到 v1 服务，否则路由到 v2 服务
    - match:
      - uri:
          prefix: /api/v1
      route:
      - destination:
          host: nginx
          subset: v1
    - route:
      - destination:
          host: nginx
          subset: v2
  ```
  - 每个虚拟服务可以定义一组 route 规则。
    - 处理流量时，会从上到下检查各个 route 规则。如果流量匹配一个 route 规则，则立即生效，否则继续检查后面的 route 规则。
  - 如果一个 route 规则没有 match 条件，则会匹配所有流量，除非这些流量先匹配了前面的 route 规则。
    - 建议在每个虚拟服务的最后定义一个没有 match 条件的 route 规则，作为默认路由。

- VirtualService 可对 http、tls、tcp 三种流量进行路由：
  ```yml
  tls:
  - match:
    - port: 443
      sniHosts:
      - test.com
    route:
    - destination:
        host: nginx
  ```
  ```yml
  tcp:
  - match:
    - port: 27017
    route:
    - destination:
        host: mongo.default.svc.cluster.local
        port:
          number: 27017
  ```

- 路由规则的详细示例：
  ```yml
  - match:
    - uri:
        prefix: /api/v1
    rewrite:              # 可以在路由转发之前，修改 uri
      uri: /api/v2
    route:
    - destination:
        host: nginx
        subset: v1
      weight: 70          # 一个 route 规则可定义多个 destination ，按百分比权重分配流量
    - destination:
        host: nginx
        port:             # 如果 upstream 为 k8s service ，且只定义了一个端口，则可省略端口号
          number: 80
        subset: v2
      weight: 30
      headers:            # 用于修改请求报文、响应报文的 headers
        request:
          set:            # 动作可以是 set、add、remove
            version: v1
          add:
            version: v1
        response:
          remove:
          - version
    name: route-v1        # 可选给路由规则命名，会记录在访问日志中
    timeout: 5s           # 将 HTTP 请求路由转发给 upstream 时，如果超过一定时长未返回 HTTP 响应，则请求失败。默认不限制超时
    retries:              # 路由转发给 upstream 时，如果转发 HTTP 请求失败，是否自动重试
      attempts: 3         # 最多重试几次。重试间隔大概为 25ms
      perTryTimeout: 3s   # 每次重试的超时时间。默认继承上级的 timeout
      retryOn: connect-failure,refused-stream,503 # 在这些情况下才自动重试
  ```
  - 处理流量时，可选的操作除了 route ，还有 redirect 等：
    ```yml
    redirect:         # 返回重定向报文
      uri: /api/v1/
      # redirectCode: 301
    ```
    ```yml
    directResponse:   # 返回自定义的 HTTP 响应
      status: 503
      body:
        string: "{\"error\": \"unknown error\"}"
    headers:
      response:
        set:
          content-type: appliation/json
    ```
    ```yml
    delegate:         # 委托，将流量交给另一个 VirtualService 处理
      name: test-route
      namespace: default
    ```
    ```yml
    mirror:           # 将流量拷贝一份，发送到另一个地址，方便调试。同时该流量依然会被非 mirror 路由规则处理
      host: nginx
      subset: v2
    mirrorPercentage: # 按百分比将流量发送到 mirror ，取值范围为 0.0~100.0
      value: 100.0    # 默认为 100.0
    ```

- match 匹配条件的详细示例：
  ```yml
  match:                # match 数组中可包含多组条件，它们是 OR 的关系。流量只要满足其中一组条件，就会采用当前 route 规则
  - name: v1            # 可选给匹配条件命名，会记录在访问日志中
    uri:                # 这组条件包含了 uri、headers 两个条件，它们是 AND 的关系。流量需要同时满足它们，才算满足这组条件
      prefix: /api/v1
    headers:
      username:
        exact: test
  - uri:                    # 对 uri 进行匹配。匹配语法为 StringMatch ，可选 exact、prefix、regex 三种匹配方式
      exact: /index.html    # 字符串完全匹配
      # prefix: /index      # 字符串前缀匹配
      # regex: /index.*     # 字符串正则匹配，采用 Google RE2 语法
    # ignoreUriCase: false  # 是否不区分 uri 的大小写，默认为 false
  - port: 80
  - method:                 # 对 HTTP 请求方法进行匹配，匹配语法为 StringMatch
      exact: GET
  - headers:
      username:             # 选择 headers 中的一个字段，进行匹配，匹配语法为 StringMatch
        exact: test
  - queryParams:
      version:              # 选择 queryParams 中的一个字段，进行匹配
        exact: v1
  ```





<!-- - 目标规则（Destination Rule） -->
